# データエンジニアリング設計原則

本ドキュメントは、データエンジニアリングの中核となる設計原則を定義します。各原則について、定義、必要性、具体例、AIが実装時にどう考慮すべきかを記載します。

## Grain（粒度）の定義
- 定義: データセットが表す事実の最小単位（例: 1行=注文行、1行=ユーザー日）。
- なぜ必要か: 粒度の曖昧さは二重計上や誤結合を生み、集計の整合性を崩すため。
- 具体例: `fact_orders` は `order_id` と `order_line_id` の組み合わせで1行。
- AIの考慮点: 変換前に必ず粒度を明記し、すべての結合が粒度を壊さないことを検証する。

## FactとDimensionの分離
- 定義: Factは測定可能なイベント、Dimensionは文脈を与える属性。
- なぜ必要か: モデルの再利用性と性能が向上し、スター・スキーマが成立するため。
- 具体例: `fact_payments` は金額・時刻、`dim_customer` は顧客属性。
- AIの考慮点: 指標と属性を早期に分類し、Factに属性を混在させない。

## Core層とMart層の分離
- 定義: Coreは整形済みの共通エンティティ、Martは用途別に最適化された派生データ。
- なぜ必要か: エンタープライズ真実とレポート用途を分離し重複を防ぐため。
- 具体例: `core_customer` は共通、`mart_revenue_by_channel` は用途別。
- AIの考慮点: まずCoreを構築し、その上にMartを積み上げる。

## Incremental処理
- 定義: 直近の変更分のみを処理する方式。
- なぜ必要か: コスト削減と性能向上、大規模データの運用に必須。
- 具体例: `updated_at > max(updated_at)` の条件で差分のみ取り込む。
- AIの考慮点: 変更キーの安定性、遅延到着データの扱いを設計に含める。

## 冪等性（Idempotency）
- 定義: 同一入力で再実行しても同一結果になる性質。
- なぜ必要か: リトライや再実行時の重複・不整合を防ぐため。
- 具体例: 盲目的なappendではなくmerge/upsertを使う。
- AIの考慮点: 一意キーとマージ条件を明確化し、再実行可能な処理にする。

## Partition設計
- 定義: クエリ効率のためにデータを分割配置する設計。
- なぜ必要か: 読み取り範囲を減らし、性能とコストを最適化するため。
- 具体例: S3で `dt=YYYY-MM-DD` によるパーティション分割。
- AIの考慮点: フィルタ条件とデータ量を基に適切な分割単位を選ぶ。

## データLineage
- 定義: データがどのソースからどの変換を経て到達したかの追跡性。
- なぜ必要か: 監査、デバッグ、影響分析に必須。
- 具体例: MartがCoreを参照し、CoreがRawを参照する関係を明記。
- AIの考慮点: 依存関係を文章やメタデータで明示する。

## スケーラビリティ設計
- 定義: データ量や利用者増加に耐えられる設計。
- なぜ必要か: 成長とともに性能劣化やコスト急増を防ぐため。
- 具体例: 分散処理、パーティション、インクリメンタル化。
- AIの考慮点: データ成長見込みに基づき最適化案を提示する。

## Single Source of Truth（SSOT）
- 定義: ある概念に対して唯一の正のデータソースを持つこと。
- なぜ必要か: 指標の不一致を防ぎ、全社的整合性を担保するため。
- 具体例: `core_orders` をすべてのMartが参照する。
- AIの考慮点: 重複定義を避け、正のソースを明記する。
